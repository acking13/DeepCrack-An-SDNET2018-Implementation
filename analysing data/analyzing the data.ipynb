{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45df80a2-b272-4642-8635-10486795382d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing 'cracked' category at: C:\\Users\\acking\\Desktop\\project\\DeepCrack-An-SDNET2018-Implementation\\raw data\\Walls\\cracked ---\n",
      "\n",
      "--- Analyzing 'non-cracked' category at: C:\\Users\\acking\\Desktop\\project\\DeepCrack-An-SDNET2018-Implementation\\raw data\\Walls\\non-cracked ---\n",
      "\n",
      "=======================================================\n",
      "           DATASET PRE-TRAINING ANALYSIS\n",
      "=======================================================\n",
      "\n",
      "--- Category: CRACKED ---\n",
      "Total Files Scanned: 3851\n",
      "Valid Images Found:  3851\n",
      "Files Skipped/Errors: 0\n",
      "\n",
      "  >> IMAGE DIMENSIONS (Size Distribution):\n",
      "    - 256x256: 3851 images (100.00%)\n",
      "  * Uniformity Check: All images have the same size.\n",
      "\n",
      "  >> COLOR MODES (RGB, Grayscale 'L', etc.):\n",
      "    - RGB: 3851 images (100.00%)\n",
      "  * Color Mode Check: All images have the same mode.\n",
      "\n",
      "--- Category: NON-CRACKED ---\n",
      "Total Files Scanned: 14287\n",
      "Valid Images Found:  14287\n",
      "Files Skipped/Errors: 0\n",
      "\n",
      "  >> IMAGE DIMENSIONS (Size Distribution):\n",
      "    - 256x256: 14287 images (100.00%)\n",
      "  * Uniformity Check: All images have the same size.\n",
      "\n",
      "  >> COLOR MODES (RGB, Grayscale 'L', etc.):\n",
      "    - RGB: 14287 images (100.00%)\n",
      "  * Color Mode Check: All images have the same mode.\n",
      "\n",
      "=======================================================\n",
      "                OVERALL DATASET STATS\n",
      "=======================================================\n",
      "Total Valid Images in Dataset: 18138\n",
      "Total Files Scanned (including non-images): 18138\n",
      "\n",
      "Class Distribution:\n",
      "  - Cracked:     3851 (21.23%)\n",
      "  - Non-cracked: 14287 (78.77%)\n",
      "\n",
      "*** ACTION RECOMMENDED: CLASS IMBALANCE DETECTED! ***\n",
      "The classes are imbalanced. Consider using techniques like data augmentation, class weighting, or over/undersampling during training.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import json # Used for pretty printing dictionaries\n",
    "\n",
    "# --- Configuration ---\n",
    "# NOTE: Set this to the path where your 'cracked' and 'non-cracked' folders reside.\n",
    "# Updated path based on user input (C:\\Users\\acking\\Desktop\\project\\DeepCrack-An-SDNET2018-Implementation\\raw data\\Walls)\n",
    "DATA_ROOT = r'C:\\Users\\acking\\Desktop\\project\\DeepCrack-An-SDNET2018-Implementation\\raw data\\Walls'\n",
    "\n",
    "# Accepted image extensions (case-insensitive)\n",
    "IMAGE_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "\n",
    "def analyze_folder(folder_path: Path, category: str) -> dict:\n",
    "    \"\"\"\n",
    "    Analyzes all image files within a specified folder path.\n",
    "\n",
    "    Args:\n",
    "        folder_path (Path): The Path object for the category folder.\n",
    "        category (str): The name of the category (e.g., 'cracked').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing collected statistics.\n",
    "    \"\"\"\n",
    "    if not folder_path.is_dir():\n",
    "        print(f\"ERROR: Folder not found at {folder_path}\")\n",
    "        return {}\n",
    "\n",
    "    print(f\"\\n--- Analyzing '{category}' category at: {folder_path} ---\")\n",
    "\n",
    "    stats = {\n",
    "        'total_files': 0,\n",
    "        'valid_images': 0,\n",
    "        'errors': 0,\n",
    "        'sizes': Counter(),  # Stores (width, height) tuples\n",
    "        'modes': Counter()   # Stores color modes (e.g., 'RGB', 'L')\n",
    "    }\n",
    "\n",
    "    # Use rglob to recursively find all files with specified extensions\n",
    "    for file_path in folder_path.rglob('*'):\n",
    "        stats['total_files'] += 1\n",
    "        if file_path.suffix.lower() not in IMAGE_EXTENSIONS:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with Image.open(file_path) as img:\n",
    "                # Store size as a string for cleaner Counter keys and output\n",
    "                size_str = f\"{img.size[0]}x{img.size[1]}\"\n",
    "                stats['sizes'][size_str] += 1\n",
    "                stats['modes'][img.mode] += 1\n",
    "                stats['valid_images'] += 1\n",
    "        except Exception as e:\n",
    "            # Catch errors like file not being a valid image or corruption\n",
    "            print(f\"Warning: Could not process {file_path.name}. Error: {e}\")\n",
    "            stats['errors'] += 1\n",
    "\n",
    "    return stats\n",
    "\n",
    "def print_summary(results: dict):\n",
    "    \"\"\"Prints a formatted summary report of the dataset analysis.\"\"\"\n",
    "\n",
    "    print(\"\\n=======================================================\")\n",
    "    print(f\"           DATASET PRE-TRAINING ANALYSIS\")\n",
    "    print(\"=======================================================\")\n",
    "\n",
    "    total_images_dataset = 0\n",
    "    total_files_dataset = 0\n",
    "\n",
    "    # 1. Category Summary\n",
    "    for category, stats in results.items():\n",
    "        total_images_dataset += stats.get('valid_images', 0)\n",
    "        total_files_dataset += stats.get('total_files', 0)\n",
    "\n",
    "        print(f\"\\n--- Category: {category.upper()} ---\")\n",
    "        print(f\"Total Files Scanned: {stats.get('total_files', 0)}\")\n",
    "        print(f\"Valid Images Found:  {stats.get('valid_images', 0)}\")\n",
    "        print(f\"Files Skipped/Errors: {stats.get('errors', 0)}\")\n",
    "\n",
    "        if stats['valid_images'] > 0:\n",
    "            print(\"\\n  >> IMAGE DIMENSIONS (Size Distribution):\")\n",
    "            # Get the 5 most common sizes\n",
    "            common_sizes = stats['sizes'].most_common(5)\n",
    "            for size, count in common_sizes:\n",
    "                percentage = (count / stats['valid_images']) * 100\n",
    "                print(f\"    - {size}: {count} images ({percentage:.2f}%)\")\n",
    "            \n",
    "            # Check for uniformity\n",
    "            if len(stats['sizes']) == 1:\n",
    "                 print(\"  * Uniformity Check: All images have the same size.\")\n",
    "            else:\n",
    "                 print(f\"  * Uniformity Check: Found {len(stats['sizes'])} unique sizes. Standardizing image size during pre-processing is recommended.\")\n",
    "\n",
    "\n",
    "            print(\"\\n  >> COLOR MODES (RGB, Grayscale 'L', etc.):\")\n",
    "            for mode, count in stats['modes'].items():\n",
    "                percentage = (count / stats['valid_images']) * 100\n",
    "                print(f\"    - {mode}: {count} images ({percentage:.2f}%)\")\n",
    "            \n",
    "            # Check for uniformity\n",
    "            if len(stats['modes']) > 1:\n",
    "                print(\"  * Color Mode Check: Found mixed color modes. Ensure you convert all images (e.g., to 'RGB') before feeding them to the network.\")\n",
    "            else:\n",
    "                print(\"  * Color Mode Check: All images have the same mode.\")\n",
    "\n",
    "\n",
    "    # 2. Overall Dataset Summary\n",
    "    print(\"\\n=======================================================\")\n",
    "    print(\"                OVERALL DATASET STATS\")\n",
    "    print(\"=======================================================\")\n",
    "    \n",
    "    # Calculate category balance\n",
    "    cracked_count = results.get('cracked', {}).get('valid_images', 0)\n",
    "    non_cracked_count = results.get('non-cracked', {}).get('valid_images', 0)\n",
    "\n",
    "    if total_images_dataset > 0:\n",
    "        cracked_pct = (cracked_count / total_images_dataset) * 100\n",
    "        non_cracked_pct = (non_cracked_count / total_images_dataset) * 100\n",
    "    else:\n",
    "        cracked_pct = 0\n",
    "        non_cracked_pct = 0\n",
    "\n",
    "    print(f\"Total Valid Images in Dataset: {total_images_dataset}\")\n",
    "    print(f\"Total Files Scanned (including non-images): {total_files_dataset}\")\n",
    "    print(f\"\\nClass Distribution:\")\n",
    "    print(f\"  - Cracked:     {cracked_count} ({cracked_pct:.2f}%)\")\n",
    "    print(f\"  - Non-cracked: {non_cracked_count} ({non_cracked_pct:.2f}%)\")\n",
    "\n",
    "    # Final advice\n",
    "    if abs(cracked_pct - non_cracked_pct) > 10 and total_images_dataset > 0:\n",
    "        print(\"\\n*** ACTION RECOMMENDED: CLASS IMBALANCE DETECTED! ***\")\n",
    "        print(\"The classes are imbalanced. Consider using techniques like data augmentation, class weighting, or over/undersampling during training.\")\n",
    "    elif total_images_dataset == 0:\n",
    "        print(\"\\n*** WARNING: ZERO VALID IMAGES FOUND. ***\")\n",
    "        print(\"Please check that the 'DATA_ROOT' path and the folder names ('cracked', 'non-cracked') are correct.\")\n",
    "    else:\n",
    "        print(\"\\nData distribution appears reasonably balanced.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the analysis.\"\"\"\n",
    "    data_root_path = Path(DATA_ROOT)\n",
    "    \n",
    "    # Define the two mandatory categories\n",
    "    cracked_path = data_root_path / 'cracked'\n",
    "    non_cracked_path = data_root_path / 'non-cracked'\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Analyze both folders\n",
    "    results['cracked'] = analyze_folder(cracked_path, 'cracked')\n",
    "    results['non-cracked'] = analyze_folder(non_cracked_path, 'non-cracked')\n",
    "    \n",
    "    # Print combined summary\n",
    "    print_summary(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure you have Pillow installed: pip install Pillow\n",
    "    # Set up a dummy folder structure for testing the script logic\n",
    "    if not Path(DATA_ROOT).exists():\n",
    "         print(f\"Note: Could not find the main data folder at: '{DATA_ROOT}'.\")\n",
    "         print(\"      Please ensure this path exists and contains the 'cracked' and 'non-cracked' subfolders.\")\n",
    "         # Removed dummy folder creation since we are using a specific, absolute path now\n",
    "    \n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d33ef8-4a59-4cba-80bf-5311c6ac7dec",
   "metadata": {},
   "source": [
    "# create a function for  reducing the brightness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d64cb3-b3c1-424a-b951-1506619e88b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageEnhance\n",
    "from typing import Tuple, List\n",
    "\n",
    "# --- Configuration ---\n",
    "# Data root path from the previous analysis step\n",
    "DATA_ROOT = r'C:\\Users\\acking\\Desktop\\project\\DeepCrack-An-SDNET2018-Implementation\\raw data\\Walls'\n",
    "\n",
    "# Standard size required for the neural network input (H, W)\n",
    "# UPDATED: Changed from (128, 128) to (256, 256) based on your input.\n",
    "TARGET_SIZE: Tuple[int, int] = (256, 256) \n",
    "\n",
    "# Factor to increase brightness: 1.0 is no change, 1.5 is a 50% increase\n",
    "BRIGHTNESS_FACTOR: float = 2 \n",
    "\n",
    "# Accepted image extensions\n",
    "IMAGE_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "\n",
    "def load_and_preprocess_data(root_dir: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Loads images from 'cracked' and 'non-cracked' subfolders, applies \n",
    "    brightness enhancement, resizing, and normalization, and prepares \n",
    "    NumPy arrays for model training.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): The path containing the 'cracked' and 'non-cracked' folders.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: X (image data) and y (labels).\n",
    "    \"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    data: List[np.ndarray] = []\n",
    "    labels: List[int] = []\n",
    "    \n",
    "    # Define categories and their corresponding labels\n",
    "    categories = {\n",
    "        'cracked': 1,\n",
    "        'non-cracked': 0\n",
    "    }\n",
    "    \n",
    "    print(f\"Starting data preprocessing...\")\n",
    "    print(f\"Target Size: {TARGET_SIZE}, Brightness Factor: {BRIGHTNESS_FACTOR}\")\n",
    "    \n",
    "    for category, label in categories.items():\n",
    "        folder_path = root_path / category\n",
    "        \n",
    "        if not folder_path.is_dir():\n",
    "            print(f\"Warning: Category folder not found: {folder_path}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nProcessing category '{category}' (Label {label})...\")\n",
    "        count = 0\n",
    "\n",
    "        # Recursively find all valid image files\n",
    "        for file_path in folder_path.rglob('*'):\n",
    "            if file_path.suffix.lower() not in IMAGE_EXTENSIONS:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # 1. Load and Standardize Size (and convert to RGB for consistency)\n",
    "                with Image.open(file_path).convert('RGB') as img:\n",
    "                    # Resize to the target size (which is now 256x256)\n",
    "                    img_resized = img.resize(TARGET_SIZE)\n",
    "                    \n",
    "                    # 2. Increase Brightness (Enhancement)\n",
    "                    enhancer = ImageEnhance.Brightness(img_resized)\n",
    "                    img_enhanced = enhancer.enhance(BRIGHTNESS_FACTOR)\n",
    "                    \n",
    "                    # 3. Normalize (Convert to array and scale)\n",
    "                    # Convert PIL image to NumPy array (dtype float32 for deep learning)\n",
    "                    img_array = np.array(img_enhanced, dtype=np.float32)\n",
    "                    \n",
    "                    # Normalize pixel values from 0-255 to 0.0-1.0\n",
    "                    normalized_array = img_array / 255.0\n",
    "                    \n",
    "                    # 4. Collect Data and Labels\n",
    "                    data.append(normalized_array)\n",
    "                    labels.append(label)\n",
    "                    count += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path.name}: {e}. Skipping.\")\n",
    "\n",
    "        print(f\"Successfully processed {count} images for '{category}'.\")\n",
    "\n",
    "    if not data:\n",
    "        print(\"\\nFATAL: No valid images were processed. Check DATA_ROOT path and subfolders.\")\n",
    "        return np.array([]), np.array([])\n",
    "        \n",
    "    # Convert lists to final NumPy arrays\n",
    "    X = np.array(data)\n",
    "    y = np.array(labels)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def main():\n",
    "    \"\"\"Executes the data preprocessing and reports the output array shapes.\"\"\"\n",
    "    \n",
    "    # Check if the main data root exists before starting\n",
    "    if not Path(DATA_ROOT).is_dir():\n",
    "        print(f\"ERROR: The main data root directory does not exist at: {DATA_ROOT}\")\n",
    "        print(\"Please verify the path and ensure it contains 'cracked' and 'non-cracked' folders.\")\n",
    "        return\n",
    "\n",
    "    # Load and preprocess the data\n",
    "    X, y = load_and_preprocess_data(DATA_ROOT)\n",
    "    \n",
    "    print(\"\\n=======================================================\")\n",
    "    print(\"           PREPROCESSED DATA SUMMARY\")\n",
    "    print(\"=======================================================\")\n",
    "\n",
    "    if X.size > 0:\n",
    "        # X shape is (Number of Images, Height, Width, Channels)\n",
    "        print(f\"Image Data (X) Shape: {X.shape}\") \n",
    "        # y shape is (Number of Images,)\n",
    "        print(f\"Label Data (y) Shape: {y.shape}\")\n",
    "        \n",
    "        print(\"\\nData is now ready for model training:\")\n",
    "        print(\"  - Images are resized to {}x{}.\".format(*TARGET_SIZE))\n",
    "        print(f\"  - Brightness increased by {BRIGHTNESS_FACTOR * 100 - 100:.0f}%.\")\n",
    "        print(\"  - Pixel values are normalized to the [0.0, 1.0] range.\")\n",
    "        print(\"You can now split X and y into training and validation sets.\")\n",
    "    else:\n",
    "        print(\"No data was successfully loaded or processed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure you have the required libraries installed:\n",
    "    # pip install Pillow numpy\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
