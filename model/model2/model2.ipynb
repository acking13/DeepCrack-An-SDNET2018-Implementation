{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2d055-42f1-4947-a749-823664ef8936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade62e82-f5d5-4343-9d52-46049f39fc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Starting data preprocessing...\n",
      "\n",
      "Processing category 'cracked' (Label 1)...\n",
      "Successfully processed 846 images for 'cracked'.\n",
      "\n",
      "Processing category 'non-cracked' (Label 0)...\n",
      "Successfully processed 873 images for 'non-cracked'.\n",
      "\n",
      "Splitting data into training (80%) and testing (20%) sets...\n",
      "Training images: 1375, Testing images: 344\n",
      "Building CNN model...\n",
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 127, 127, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 127, 127, 32)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 62, 62, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 115200)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               14745728  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14839105 (56.61 MB)\n",
      "Trainable params: 14839105 (56.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting model training...\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "43/43 [==============================] - 85s 2s/step - loss: 0.9615 - accuracy: 0.4887 - val_loss: 0.6931 - val_accuracy: 0.5087\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 72s 2s/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6930 - val_accuracy: 0.5087\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 69s 2s/step - loss: 0.6931 - accuracy: 0.5076 - val_loss: 0.6930 - val_accuracy: 0.5087\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 81s 2s/step - loss: 0.6931 - accuracy: 0.5076 - val_loss: 0.6930 - val_accuracy: 0.5087\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - 97s 2s/step - loss: 0.6931 - accuracy: 0.5076 - val_loss: 0.6930 - val_accuracy: 0.5087\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - 165s 4s/step - loss: 0.6931 - accuracy: 0.5076 - val_loss: 0.6930 - val_accuracy: 0.5087\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - 233s 5s/step - loss: 0.6930 - accuracy: 0.5076 - val_loss: 0.6930 - val_accuracy: 0.5087\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - 228s 5s/step - loss: 0.6926 - accuracy: 0.5076 - val_loss: 0.6930 - val_accuracy: 0.5087\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - 212s 5s/step - loss: 0.6931 - accuracy: 0.5076 - val_loss: 0.6930 - val_accuracy: 0.5087\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - 203s 5s/step - loss: 0.6932 - accuracy: 0.5076 - val_loss: 0.6930 - val_accuracy: 0.5087\n",
      "\n",
      "=======================================================\n",
      "           MODEL EVALUATION ON TEST DATA\n",
      "=======================================================\n",
      "Final Test Loss: 0.6930\n",
      "Final Test Accuracy: 50.87%\n",
      "11/11 [==============================] - 9s 578ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics and Confusion Matrix saved to: model_metrics.csv\n",
      "\n",
      "Five visualization charts saved as PNG files (1-5.png) in the current directory.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Import necessary components for preprocessing (copied from image_preprocessor.py)\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageEnhance\n",
    "from typing import Tuple, List\n",
    "\n",
    "# --- Preprocessing Configuration (Copied from image_preprocessor.py) ---\n",
    "DATA_ROOT = r'C:\\Users\\acking\\Desktop\\project\\DeepCrack-An-SDNET2018-Implementation\\raw data\\Walls - Copy'\n",
    "TARGET_SIZE: Tuple[int, int] = (256, 256) \n",
    "BRIGHTNESS_FACTOR: float = 1.5 \n",
    "IMAGE_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "\n",
    "def load_and_preprocess_data(root_dir: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Loads images and applies the requested preprocessing steps: \n",
    "    Brightness enhancement, resizing, and normalization.\n",
    "    \"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    data: List[np.ndarray] = []\n",
    "    labels: List[int] = []\n",
    "    \n",
    "    categories = {'cracked': 1, 'non-cracked': 0}\n",
    "    print(f\"Starting data preprocessing...\")\n",
    "    \n",
    "    for category, label in categories.items():\n",
    "        folder_path = root_path / category\n",
    "        if not folder_path.is_dir():\n",
    "            print(f\"Warning: Category folder not found: {folder_path}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nProcessing category '{category}' (Label {label})...\")\n",
    "        count = 0\n",
    "\n",
    "        for file_path in folder_path.rglob('*'):\n",
    "            if file_path.suffix.lower() not in IMAGE_EXTENSIONS:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with Image.open(file_path).convert('RGB') as img:\n",
    "                    img_resized = img.resize(TARGET_SIZE)\n",
    "                    \n",
    "                    # 2. Increase Brightness (Enhancement)\n",
    "                    enhancer = ImageEnhance.Brightness(img_resized)\n",
    "                    img_enhanced = enhancer.enhance(BRIGHTNESS_FACTOR)\n",
    "                    \n",
    "                    # 3. Normalize (Convert to array and scale)\n",
    "                    img_array = np.array(img_enhanced, dtype=np.float32)\n",
    "                    normalized_array = img_array / 255.0\n",
    "                    \n",
    "                    data.append(normalized_array)\n",
    "                    labels.append(label)\n",
    "                    count += 1\n",
    "                    \n",
    "            except Exception:\n",
    "                pass \n",
    "\n",
    "        print(f\"Successfully processed {count} images for '{category}'.\")\n",
    "\n",
    "    if not data:\n",
    "        print(\"\\nFATAL: No valid images were processed. Cannot build model.\")\n",
    "        return np.array([]), np.array([])\n",
    "        \n",
    "    X = np.array(data)\n",
    "    y = np.array(labels)\n",
    "    return X, y\n",
    "\n",
    "def build_cnn_model(input_shape: Tuple[int, int, int]) -> Sequential:\n",
    "    \"\"\"\n",
    "    Defines a simple Convolutional Neural Network (CNN) architecture with Dropout.\n",
    "    \"\"\"\n",
    "    print(\"Building CNN model...\")\n",
    "    model = Sequential([\n",
    "        # Block 1: Feature Extraction\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25), # Added Dropout to mitigate overfitting\n",
    "\n",
    "        # Block 2\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        # Block 3\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Classification Head\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5), # Heavier dropout before the final layer\n",
    "        Dense(1, activation='sigmoid') \n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def save_error_metrics_csv(y_test: np.ndarray, y_pred_class: np.ndarray, file_path: Path):\n",
    "    \"\"\"\n",
    "    Calculates Confusion Matrix and Classification Report and saves them to a CSV file.\n",
    "    \"\"\"\n",
    "    # Calculate the Confusion Matrix (the 'matrix of errors')\n",
    "    cm = confusion_matrix(y_test, y_pred_class)\n",
    "    cm_df = pd.DataFrame(cm, \n",
    "                         index=['Actual Non-Cracked', 'Actual Cracked'], \n",
    "                         columns=['Predicted Non-Cracked', 'Predicted Cracked'])\n",
    "    \n",
    "    # Calculate the Classification Report (the 'error metrix')\n",
    "    report = classification_report(y_test, y_pred_class, target_names=['Non-Cracked (0)', 'Cracked (1)'], output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "    # Combine data into a single CSV\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(\"--- Confusion Matrix ---\\n\")\n",
    "        cm_df.to_csv(f)\n",
    "        f.write(\"\\n--- Classification Report (Error Metrics) ---\\n\")\n",
    "        report_df.to_csv(f)\n",
    "\n",
    "    print(f\"\\nMetrics and Confusion Matrix saved to: {file_path.name}\")\n",
    "\n",
    "\n",
    "def generate_plots(history: tf.keras.callbacks.History, y_test: np.ndarray, y_pred_proba: np.ndarray):\n",
    "    \"\"\"\n",
    "    Generates and saves five charts visualizing training history and model performance.\n",
    "    \"\"\"\n",
    "    history_dict = history.history\n",
    "    epochs = range(1, len(history_dict['loss']) + 1)\n",
    "    \n",
    "    # --- Chart 1: Accuracy History ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs, history_dict['accuracy'], 'bo', label='Training Acc')\n",
    "    plt.plot(epochs, history_dict['val_accuracy'], 'b', label='Validation Acc')\n",
    "    plt.title('1. Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig('accuracy_history.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # --- Chart 2: Loss History ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs, history_dict['loss'], 'ro', label='Training Loss')\n",
    "    plt.plot(epochs, history_dict['val_loss'], 'r', label='Validation Loss')\n",
    "    plt.title('2. Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('loss_history.png')\n",
    "    plt.close()\n",
    "\n",
    "    # --- Chart 3: Confusion Matrix ---\n",
    "    cm = confusion_matrix(y_test, (y_pred_proba > 0.5).astype(\"int32\"))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('3. Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, ['Non-Cracked', 'Cracked'])\n",
    "    plt.yticks(tick_marks, ['Non-Cracked', 'Cracked'])\n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "    # --- Chart 4: ROC Curve ---\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    plt.title('4. Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('roc_curve.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # --- Chart 5: Precision-Recall Curve ---\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, color='purple', lw=2, label='Precision-Recall curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('5. Precision-Recall Curve')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig('precision_recall_curve.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\nFive visualization charts saved as PNG files (1-5.png) in the current directory.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to load data, train, evaluate, and generate reports.\"\"\"\n",
    "    \n",
    "    # --- 1. Load and Preprocess Data ---\n",
    "    if not Path(DATA_ROOT).is_dir():\n",
    "        print(f\"ERROR: The main data root directory does not exist at: {DATA_ROOT}\")\n",
    "        print(\"Please verify the path and ensure it contains 'cracked' and 'non-cracked' folders.\")\n",
    "        return\n",
    "\n",
    "    X, y = load_and_preprocess_data(DATA_ROOT)\n",
    "    \n",
    "    if X.size == 0:\n",
    "        return\n",
    "\n",
    "    input_shape = X.shape[1:] \n",
    "\n",
    "    # --- 2. Split Data ---\n",
    "    print(\"\\nSplitting data into training (80%) and testing (20%) sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    print(f\"Training images: {X_train.shape[0]}, Testing images: {X_test.shape[0]}\")\n",
    "    \n",
    "    # --- 3. Build Model (Note: Added Dropout layers to mitigate overfitting) ---\n",
    "    model = build_cnn_model(input_shape)\n",
    "    model.summary()\n",
    "\n",
    "    # --- 4. Train Model ---\n",
    "    print(\"\\nStarting model training...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=10, \n",
    "        batch_size=32,\n",
    "        validation_data=(X_test, y_test),\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # --- 5. Evaluate Model & Generate Reports ---\n",
    "    print(\"\\n=======================================================\")\n",
    "    print(\"           MODEL EVALUATION ON TEST DATA\")\n",
    "    print(\"=======================================================\")\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    print(f\"Final Test Loss: {loss:.4f}\")\n",
    "    print(f\"Final Test Accuracy: {accuracy*100:.2f}%\")\n",
    "    \n",
    "    # Get probability predictions and convert them to class predictions (0 or 1)\n",
    "    y_pred_proba = model.predict(X_test).ravel()\n",
    "    y_pred_class = (y_pred_proba > 0.5).astype(\"int32\")\n",
    "\n",
    "    # Generate and save the CSV of metrics and Confusion Matrix\n",
    "    save_error_metrics_csv(y_test, y_pred_class, Path('model_metrics.csv'))\n",
    "    \n",
    "    # Generate and save the five requested charts\n",
    "    generate_plots(history, y_test, y_pred_proba)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
